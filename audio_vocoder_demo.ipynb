{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e8d329f",
   "metadata": {},
   "source": [
    "# Audio Recording and Vocoder Demo\n",
    "\n",
    "This notebook lets you record audio, convert it to a mel spectrogram, and synthesize audio using a vocoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4e0cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install sounddevice torchaudio numpy IPython\n",
    "\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import torch\n",
    "from IPython.display import Audio, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12c582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record audio from microphone\n",
    "SAMPLE_RATE = 22050  # Match vocoder's expected sample rate\n",
    "DURATION = 5  # seconds\n",
    "print(f\"Recording for {DURATION} seconds...\")\n",
    "audio = sd.rec(int(DURATION * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=1, dtype='float32')\n",
    "sd.wait()\n",
    "print(\"Recording complete.\")\n",
    "\n",
    "# Listen to the recorded audio\n",
    "Audio(audio.T, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5adfddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert audio to mel spectrogram\n",
    "\n",
    "audio_tensor = torch.from_numpy(audio.T)\n",
    "if audio_tensor.dim() == 1:\n",
    "    audio_tensor = audio_tensor.unsqueeze(0)\n",
    "\n",
    "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
    "    sample_rate=SAMPLE_RATE,\n",
    "    n_fft=1024,\n",
    "    hop_length=256,\n",
    "    n_mels=80\n",
    ")\n",
    "mel_spec = mel_transform(audio_tensor)\n",
    "mel_spec_db = torchaudio.functional.amplitude_to_DB(mel_spec, multiplier=10.0, amin=1e-10, db_multiplier=0)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.imshow(mel_spec_db.squeeze().numpy(), aspect='auto', origin='lower')\n",
    "plt.title('Mel Spectrogram (dB)')\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Mel Bin')\n",
    "plt.colorbar(format='%+2.0f dB')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8cfab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained HiFi-GAN vocoder from torchaudio\n",
    "bundle = torchaudio.pipelines.HIFIGAN_VOCODER_VCTK\n",
    "vocoder = bundle.get_vocoder().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eec4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate audio from mel spectrogram and play it\n",
    "with torch.no_grad():\n",
    "    # HiFi-GAN expects (batch, n_mels, frames)\n",
    "    mel_for_vocoder = mel_spec\n",
    "    if mel_for_vocoder.dim() == 2:\n",
    "        mel_for_vocoder = mel_for_vocoder.unsqueeze(0)\n",
    "    audio_out = vocoder(mel_for_vocoder)\n",
    "\n",
    "# Play the generated audio\n",
    "Audio(audio_out.squeeze().cpu().numpy(), rate=SAMPLE_RATE)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
